# -*- coding: utf-8 -*-
"""
Created on Sat Nov 10 17:04:25 2018
https://www.geeksforgeeks.org/python-pandas-dataframe-isin/

pip install dask[dataframe]

from datetime import datetime

datelist =[(datetime.today() + dateutil.relativedelta.relativedelta(months=x)).strftime("%Y-%m-01") for x in range(-12, 1)]


df=pd.DataFrame({'Date':datelist})

variables = locals()
variables["df{0}".format(num)] =df

@author: Ronny
"""
import pandas as pd
import numpy as np

#start dates
import dateutil.relativedelta 
import time
from datetime import datetime

start_time = time.time()
updated=time.strftime("%Y%m%d")
period_start = (datetime.today()- relativedelta(months=1)).strftime("%Y%m01")
period_end = (datetime.today()+ relativedelta(months=4)).strftime("%Y%m%d")
last_day_month=(datetime.today() + 
   dateutil.relativedelta.relativedelta(months=1)+
   dateutil.relativedelta.relativedelta(day=31)).strftime("%Y-%m-%d")


df1['USDMean'] = df1.groupby(['DateKey'])['USD'].transform(lambda x : x.mean())

#loop thru periods


#daily D, Monthy MS, Yearly YS

import pandas as pd
import dateutil.relativedelta
import time
from datetime import datetime

Today=time.strftime("%Y-%m-%d")
period_start = (datetime.today() - dateutil.relativedelta.relativedelta(months=1)).strftime("%Y-%m-%d")
period_end = (datetime.today() - dateutil.relativedelta.relativedelta(months=1)).strftime("%Y-%m-%d")
def create_date_table2(start, end):
    df = pd.DataFrame({"Date": pd.date_range(start, end,freq='YS')})
    df['AR1']= df.Date.dt.strftime('%Y').astype(int)
    df['AR2']= df.AR1-1
    df['Period']=df.AR2.astype(str).str.cat([df.AR1.astype(str)],sep='-')
    df['AR1x']= df.Date.dt.strftime('%y').astype(int)
    df['AR2x']= df.AR1x-1
    df['Periodx']=df.AR2x.astype(str).str.cat([df.AR1x.astype(str)],sep='')
    return df
df=create_date_table2(start=period_start, end=period_end)


period_l=list(df.Period) #period_l = df1.Period.tolist()

#freq
df.HomeTeam.value_counts()

    df['BalansResultat'] = np.where(df.Konto.isin(balansrakning), 'Balansräkning','Resultaträkning')

#qlist


lista='london paris frag2_3 v b gggg khk hgg    jjj'

qlist=pd.DataFrame({'Cols':lista.split(' ')})
qlist=qlist.query('Cols not in [""]')
qlist['ff']='x.'+qlist.Cols
data=list(qlist.ff)
data=tuple(qlist.ff)


lista='Value konton'

columns_to_numeric=[item for item in lista.title().split(' ') if  item not in  ['']]

df[columns_to_numeric] = df[columns_to_numeric].apply(pd.to_numeric, errors='coerce')


import pandas as pd
from datetime import datetime


qlist=pd.DataFrame({'Date':[datetime.today()]})
qlist['period_start']=((qlist.Date - pd.DateOffset(months=1)).dt.to_period("m").dt.start_time).dt.strftime("%Y-%m-%d")
qlist['period_End']=((qlist.Date + pd.DateOffset(months=1)).dt.to_period("m").dt.end_time).dt.strftime("%Y-%m-%d")

Min_date="[]".join(list(qlist.period_start))
Max_date="[]".join(list(qlist.period_End))

#keep colums

df1=df.loc[:, keepPeriod1].copy()

#Y M Q W: first last days
df['xx'] = df.Date.dt.to_period("Y").dt.end_time
df['xxc'] = df.Date.dt.to_period("W").dt.start_time

lista="age guy girl boy n"

new_list=lista.split(' ')
while ("" in new_list):
    new_list.remove("")

new_tuple=tuple(lista.split(' '))

df=pd.DataFrame({"Col_name":new_list})
df['ID']=df.index+1
df['Dtype']='text'
df.loc[(df.ID ==1) , 'Dtype'] = 'date'
df['New_col']=df.Col_name+' '+df.Dtype

lista=("vernr Bokforingsdatum Registreringsdatum Konto Benamning"
       "Ks Projnr Verifikationstext Transaktionsinfo Debet Kredit")
Col_names=lista.split(' ')
while ("" in Col_names):
    Col_names.remove("")

df_tmp.columns=Col_names


period_s=list(df.Periodx)  #period_s = df1.Periodx.tolist()
for yyyymm,yymm in zip(period_l, period_s):
    print(yyyymm,yymm)


list = ["boat", "car", "plane"]

# Call enumerate to loop over indexes and values.
for i, v in enumerate(list):
    print(i, v)

df.drop(['IDx', 'idxx'], axis=1,inplace=True) 
df1=df.describe(include=[np.number]).T
df1=df.describe(include=[np.object,pd.Categorical]).T

#delete dataframes
import gc        
del [[df,df2,df_date,Datum]]
gc.collect()

#begin dates

*dates

import pandas as pd
from pandas.tseries.offsets import MonthEnd

Datum='2018-11-19'
dataset="df_date"
globals()[str(dataset)] = pd.DataFrame({'Date1': [Datum]})
globals()[str(dataset)].Date1 = globals()[str(dataset)].Date1.values.astype("datetime64[s]")
globals()[str(dataset)]['Previous_month'] = globals()[str(dataset)].Date1 - pd.DateOffset(months=24)
globals()[str(dataset)]['Next_month'] = globals()[str(dataset)].Date1 + pd.DateOffset(months=1)
globals()[str(dataset)]['Previous_Day'] = globals()[str(dataset)].Date1 - pd.DateOffset(days=1)
globals()[str(dataset)]['Previous_monthMonthBegin'] = globals()[str(dataset)].Previous_month.values.astype('datetime64[M]')
globals()[str(dataset)]['PreviousMonthEnd'] = pd.to_datetime(globals()[str(dataset)].Previous_month, format="%Y%m") + MonthEnd(0)

Mindate=globals()[str(dataset)].Previous_month.min()
Maxdate=globals()[str(dataset)].Date1.min()

df1=df.query('(Date >=@Mindate and Date<=@Maxdate) and Country in ["ESP"]')


Array_sum=['B365H','B365D','B365A','FTHG']
df['total']=df.loc[:,Array_sum].sum(axis=1)
col_list=['GDM1','GDM2','GDM3','GDM4','GDM5','GDM6']
df["PCT_B"]=df[col_list].sum(axis=1)

#%%

df = pd.read_csv('http://www.football-data.co.uk/fixtures.csv')

#substring
df['v1'] = df.Date.str[0:2]
df['v2'] = df.Date.str[3:5]
df['v3'] = '20'+df.Date.str[6:9]
df['Date1'] =df.v3+'-'+df.v2+'-'+ df.v1

#remove space in columns
df.columns = df.columns.str.replace(' ', '')


#change char
object_to_int=['Debet','Kredit','Konto']
df[object_to_int] = df[object_to_int].apply(pd.to_numeric, errors='coerce')
df.update(df[object_to_int].fillna(0))


object_to_str=['Vernr','Sheetname']
df[object_to_str] = df[object_to_str].values.astype(str)

object_to_date=['Bokforingsdatum','Registreringsdatum']

df[object_to_date] = df[object_to_date].values.astype("datetime64[s]") 

# Change the dtypes (int64 -> int32)
col_names=['col_1','col_2', 'col_3', 'col_4', 'col_5']

df[col_names] = df[col_names].astype(int)
df[col_names] = df[col_names].astype(float)
df[col_names] = df[col_names].astype(str)


import datetime as dt
df['From date to str'] = df.Bokforingsdatum.apply(lambda x: dt.datetime.strftime(x, '%Y-%m-%d'))



#multi excel

files=('all-euro-data-2017-2018.xlsx','all-euro-data-2016-2017.xlsx')
sheets=['E0','E1']


#files=('Footballteams - Copy.xlsx')
df = pd.DataFrame()
for file in files:
    df_dict = pd.read_excel(team_path+'\\'+ str(file), sheet_name=None)
    dfx = pd.concat([df_dict.values()], axis=0,sort=False,keys=sheets)
    dfx['Filename']=str(file)
    dfx['xx']=dfx.index.get_values()
    df = df.append(dfx, ignore_index=True,sort=False)

#Merge

df3=pd.merge(table1,table2[["COL1","COL2"]],how="left",left_on=["VAR1","T1"],right_on=["VAR2",T3],indicator=True)

#sort

df.sort_values(['Date1', 'HomeTeam'], ascending=[True, False],inplace=True)

#remove duplicates

df.drop_duplicates(['Date1','HomeTeam','AwayTeam'],keep= 'last', inplace=True)
list_drop_vars=['Datekey','SalesKey']
test.drop(list_drop_vars, axis=1, inplace=True)

##date to string
df['Date2'] = df.Date1.astype(str)

#uppper lower

df.HomeTeam = df.HomeTeam.str.upper()
df.HomeTeam = df.HomeTeam.str.lower()
df.HomeTeam= df.HomeTeam.str.title()
df.columns = df.columns.str.upper()
df.columns = [col.replace(' ','_').upper() for col in df.columns]
#where statemaent
df['IsPreviousWeek']=0
df.loc[(df.BookedDate >=df.FirstDateOfWeek) & (df.BookedDate<=df.LastDateOfWeek), 'IsPreviousWeek'] = 1
df.loc[((df.test_score <=95) & (df.test_score>90)) | (df.test_score==84), 'grades'] = 'A-'


df=df.query('Div in ["E0","E1"] and B365H in [3.4]') 
df=df.query('(Div in ["E0","E1"] or HomeTeam in  ["Huddersfield"]) and v3 in ["2018"] ')
df[df['Kontoplan'].between(99, 101)] 
df.loc[df.Kontoplan.between(99, 101) , 'GrpKontoplan2'] = 'Immateriella anläggningstillgångar'

df3=df.query('Abonnentnr in @Abonnent and (Engagemangs_Datum>=@date1 and Engagemangs_Datum<=@date2 )')

#like statement
df1=df.loc[(df['Home'].str.contains('Man|pool|Gala')) ]
df1=df.loc[(df['Home'].str.contains('Man|pool|Gala')) & (df['Away'].str.contains('Nap|Tot'))]
df1=df.loc[(df['Home'].str.contains('Man|pool|Gala')) | (df['Away'].str.contains('Atl|Tot'))]
#tvätmot
df1=df.loc[(-df['Home'].str.contains('Man|pool|Gala')) & (-df['Away'].str.contains('Atl|Tot'))]

#like statement not case sensitive
import re
df1=df.loc[df['Home'].str.contains('maN|pooL|gala',flags=re.I,regex=True)   ]
df1=df.loc[(df['Home'].str.contains('Man|pool|Gala',flags=re.I,regex=True)) | (df['Away'].str.contains('Atl|Tot'))]
#begins with M or m
df1=df.loc[df['Home'].str.contains('^M[a-z]*',flags=re.I,regex=True)   ]
#begins with m M or Bb
df1=df.loc[df['Home'].str.contains('^M[a-z]*|^b[a-z]*',flags=re.I,regex=True)   ]

#ends with 
df1=df.loc[df['Home'].str.contains('city$[a-z]*',flags=re.I,regex=True)   ]

Abonnent=("C2622","A8VX1","D3130")
date1="2018-03-31"
date2="2018-04-30"
sql=''' SELECT distinct Engagemangs_Datum,Abonnentnr FROM data1 WHERE Engagemangs_Datum  between '%s' and '%s'  and  Abonnentnr  in %s ''' %(date1,date2,Abonnent)
df2 = pd.read_sql_query(sql  ,conn)

#remove all non numeric values
df['B'] = df['B'].str.replace(r'[^\d.]+', '')

#if one abbonent

Abonnent=("C2622")
date1="2018-03-31"
date2="2018-04-30"
sql=''' SELECT distinct Engagemangs_Datum,Abonnentnr FROM data1 WHERE Engagemangs_Datum  between '%s' and '%s'  and  Abonnentnr  in ("%s") ''' %(date1,date2,Abonnent)
df2 = pd.read_sql_query(sql  ,conn)

kredittyper=(1,2,5)
for kredittyp in kredittyper:
    dropTableStatement = 'DROP TABLE IF EXISTS'+' '+  'Ktp_'+str(kredittyp)
    c.execute(dropTableStatement)
    conn.execute(''' 
                 create table Ktp_%s as
                 SELECT  Engagemangs_Datum as Datum,count(*) as Antal_%s,sum(Saldo) as Saldo_%s FROM data1 
                 WHERE Kredittyp  =%s 
                 group by Engagemangs_Datum
                 ''' %(kredittyp,kredittyp,kredittyp,kredittyp) )


##date between two dates
##df1 = df[df.Date.isin(pd.date_range("2015-08-08", "2015-08-08"))]
##df1 = df[-df.Date.isin(pd.date_range("2015-08-08", "2015-08-08"))]      
#      #%%


df.loc[df['HomeTeam'].isin(['Zwolle']), 'test'] = 'sss'

#remove empty rows
df.test.fillna('isnull', inplace=True)
df1=df.query('test in ["isnull"]') 
df2=df.query('test not in ["isnull"]') 


#if else;

dataset=df_final
The_var=('Sammanfattning_')
New_var=('Rank_var')
dataset.loc[dataset[str(The_var)].isin(['NettoomsÃ¤ttning']), str(New_var)] = 1
dataset.loc[dataset[str(The_var)].isin(['Ã–vriga rÃ¶relseintÃ¤kter']), str(New_var)] = 2
dataset.loc[dataset.HomeTeam.isin([ "Aston Villa", "Everton"]) & (dataset.AwayTeam.isin(["Bolton"])), "HomeTeam1"] = "test"
dataset.loc[(dataset.Div.isin([ "E0", "E1"]) | dataset.HomeTeam.isin(['FC Koln']) ) & (dataset.AR.isin(["2017"])),"Testvar"]="Test"



#concatanate
df['com']=df.HomeTeam.str.cat([df.AwayTeam,df.Date],sep=', ')

#sort
df.sort_values(['A', 'C'], ascending=[True, False],inplace=True)

#groupby
df1=df.groupby(['Div','Sheetname'], as_index=False).agg({"FTHG": ["sum","max","min",'count','mean'],"FTAG": ["sum","max","min",'count','mean'],"Team":["nunique"]})
#denna fixar till namnen som skapas av groupby
df1.columns = ["_".join(x) for x in df1.columns.ravel()]

df1=df1.groupby(['DateKey','Currency'], as_index=False).agg({"Value": ['mean']})
df1.columns = ['DateKey','Currency','Value']


v5x=v4.query('Div in ["E0","E1"] and AR in ["2017"]').groupby(['AR','Team','Div'], as_index=False).agg({"Poang": ["sum"]})
v5=df.query('(Div in ["E0","E1"] or HomeTeam in  ["Huddersfield"]) and v3 in ["2018"] ').groupby(['AR','Team','Div'], as_index=False).agg({"Poang": ["sum",'count'],"Team":["nunique"]})

Grp_stats=['mean','count']

for stats in Grp_stats:
    v4['test'+str(stats)]=v4.groupby(['AR','Team'])[['Poang']].transform(np.str(stats))

#rename

#df.rename(columns={'GD<-5':'GDM1','GD=-5':'GDM2','GD=-4':'GDM3','GD=-3':'GDM4',
                'GD=-2':'GDM5','GD=-1':'GDM6','GD=1':'GDP1','GD=2':'GDP2',
                  'GD=3':'GDP3','GD=4':'GDP4','GD=5':'GDP5','GD>5':'GDP6','GD=0':'PCT_D'},inplace=True)


#rename vars
 #make sure of the order of the old vars
dataset=df
Old_cols  = ['GD<-5','GD=-5','GD=-4','GD=-3','GD=-2','GD=-1','GD=0','GD=1','GD=2','GD=3','GD=4','GD=5','GD>5']
new_names = ['GDM1','GDM2','GDM3','GDM4','GDM5','GDM6','PCT_D','GDP1','GDP2','GDP3','GDP4','GDP5','GDP6']
column_indices=[dataset.columns.get_loc(c) for c in dataset.columns if c in Old_cols]
old_names = dataset.columns[column_indices]
dataset.rename(columns=dict(zip(old_names, new_names)), inplace=True)

#%%timeseries

#laggar eller leadar
for shifts in range(0,3):
    v4["lastgame"+str(shifts)] = (v4.groupby(['Team', 'AR'])['Goal'].shift(shifts))


#insert empty cell with previuos
for  shifts in range(1,3):
    print(shifts)
    v4["lastgame"+str(shifts)] = np.where(v4["lastgame"+str(shifts)].isnull(),v4["lastgame"+str(shifts-1)],v4["lastgame"+str(shifts)])

df = pd.DataFrame({
    'Date': ['2017', '2017', '2018', '2018', '2018'],
    'Groups': ['one', 'one', 'one', 'two', 'two'],
'total': range(1, 6)})


v4['IDx'] = 1
v4['no_cumulative'] = v4.groupby(['Team','AR'])['Goal'].apply(lambda x: x.cumsum())
v4['idxx'] = v4.groupby(['Team','AR'])['IDx'].apply(lambda x: x.cumsum())

df['idxx'] = df.groupby(['Date','Groups'])['total'].cumsum()

v4['idxx'] = v4.groupby(['Team','AR']).cumcount()+1

df['DayOfQuarter'] = df.groupby(['QuarterCode']).cumcount()+1

df['idxxMax'] = df.groupby(['Date','Grp'])['idxx'].transform(lambda x : x.max()) #max of a group in a cloumn

#moving average

v4['MA2'] =v4.groupby('Team')['Goal'].rolling(2).mean().reset_index(0,drop=True)
v4['Cum2'] =v4.groupby('Team')['IDx'].rolling(2).sum().reset_index(0,drop=True)

#%%


#%%
#ledinzeros
df['test']=df.Var.str.pad(width=5,fillchar='0')

#Calendar

    #%%
#the calander
#dont change anything here
Min_date='2018-11-01'                   #str(globals()[str(Master_file)+'1'].Datum.min())
Max_date='2018-12-31'                  #str(globals()[str(Master_file)+'1'].Datum.max())


import pandas as pd
from datetime import timedelta
#from dateutil.relativedelta import relativedelta
from pandas.tseries.offsets import MonthEnd
#df['dates'] = pd.date_range(start='2017-01-01',end='2017-01-31',freq='D')
#daily D, Monthy MS, Yearly YS
def create_date_table2(start, end):
    df = pd.DataFrame({"Date": pd.date_range(start, end,freq='D')})
    df["Year"] = df.Date.dt.year
    df["NextYear"] = df.Date.dt.year+1
    df["DayofWeek"] = df.Date.dt.weekday_name
    df["DayNumber"] = df.Date.dt.weekday+1
    df["MonthNumber"] = df.Date.dt.month
    df["Week"] = df.Date.dt.weekofyear
    df["Qtr"] = df.Date.dt.quarter
    df['MonthBegin'] = df.Date.values.astype('datetime64[M]')
    df['MonthEnd'] = pd.to_datetime(df.Date, format="%Y%m") + MonthEnd(0)
    df['date1'] = pd.Timestamp('2019-01-01')
    df['months_between'] = (df.date1.dt.to_period('M') - df.Date.dt.to_period('M'))
    df['days_between'] = (df.date1.dt.to_period('D') - df.Date.dt.to_period('D'))
    df['weeks_between'] = (df.date1.dt.to_period('w') - df.Date.dt.to_period('w'))
    df['date_N_days_ago'] = df.Date + timedelta(days=2)
    df['Rank']= df.Date.dt.strftime('%Y%m').astype(int)
    df['Manad']= df.Date.dt.strftime('%Y-%m')
    df['MonthName']= df.Date.dt.strftime('%B')
    df['MonthName1']= df.Date.dt.strftime('%b')
    df['Previous_month'] = df.Date - pd.DateOffset(months=1)
    df['Next_month'] = df.Date + pd.DateOffset(months=1)
    df['Next_Week'] = df.Date + pd.DateOffset(weeks=1)
    df['Previous_Week'] = df.Date - pd.DateOffset(weeks=1)
    df['Next_WeekNumber'] = df.Next_Week.dt.weekofyear
    df['Previous_WeekNumber'] = df.Previous_Week.dt.weekofyear
    df['yy']= df.Date.dt.strftime('%y')
    return df

MyCalendar=create_date_table2(start=Min_date, end=Max_date)

dataset=MyCalendar
The_var=('man1')
New_var=('Month_Swe')
dataset.loc[dataset[str(The_var)].isin(['jan']), str(New_var)] = '01'
dataset.loc[dataset[str(The_var)].isin(['feb']), str(New_var)] = '02'
dataset.loc[dataset[str(The_var)].isin(['mar']), str(New_var)] = '03'
dataset.loc[dataset[str(The_var)].isin(['apr']), str(New_var)] = '04'
dataset.loc[dataset[str(The_var)].isin(['maj']), str(New_var)] = '05'
dataset.loc[dataset[str(The_var)].isin(['jun']), str(New_var)] = '06'
dataset.loc[dataset[str(The_var)].isin(['jul']), str(New_var)] = '07'
dataset.loc[dataset[str(The_var)].isin(['aug']), str(New_var)] = '08'
dataset.loc[dataset[str(The_var)].isin(['sep']), str(New_var)] = '09'
dataset.loc[dataset[str(The_var)].isin(['okt']), str(New_var)] = '10'
dataset.loc[dataset[str(The_var)].isin(['nov']), str(New_var)] = '11'
dataset.loc[dataset[str(The_var)].isin(['dec']), str(New_var)] = '12'
MyCalendar['Datum_swe']= 'x'+MyCalendar.Month_Swe+'-'+MyCalendar.yy
MyCalendar['start_next_month'] = MyCalendar.Next_month.values.astype('datetime64[M]')
#MyCalendar['Date'] = pd.to_datetime(MyCalendar.Date)

/*
dateformats


Directive 	Description 	Example 	Try it
%a 	Weekday, short version 	Wed 	
%A 	Weekday, full version 	Wednesday 	
%w 	Weekday as a number 0-6, 0 is Sunday 	3 	
%d 	Day of month 01-31 	31 	
%b 	Month name, short version 	Dec 	
%B 	Month name, full version 	December 	
%m 	Month as a number 01-12 	12 	
%y 	Year, short version, without century 	18 	
%Y 	Year, full version 	2018 	
%H 	Hour 00-23 	17 	
%I 	Hour 00-12 	05 	
%p 	AM/PM 	PM 	
%M 	Minute 00-59 	41 	
%S 	Second 00-59 	08 	
%f 	Microsecond 000000-999999 	548513 	
%z 	UTC offset 	+0100 	
%Z 	Timezone 	CST 	
%j 	Day number of year 001-366 	365 	
%U 	Week number of year, Sunday as the first day of week, 00-53 	52 	
%W 	Week number of year, Monday as the first day of week, 00-53 	52 	
%c 	Local version of date and time 	Mon Dec 31 17:41:00 2018 	
%x 	Local version of date 	12/31/18 	
%X 	Local version of time 	17:41:00 	
%% 	A % character 	%
https://www.programiz.com/python-programming/library/strftime*/




################################SQLlite

import pandas as pd
import time
import datetime
import sqlite3

sqlite3_table='Data'
table1='test'
conn = sqlite3.connect(r'C:\Users\rso363\RONSEN\Python\Konton\Database\Mytest.db')
c = conn.cursor()

t=time.clock()



dropTableStatement = 'DROP TABLE IF EXISTS'+' '+  table1
c.execute(dropTableStatement)


Col_names=['Extr_Datum','Personnr','Abonnentnr','Huvudabonnent','Kontoid','Kontonr','Engagemangs_Datum','Limit,Saldo','Kredittyp','Skötselkod','Konto_Slutdatum','Laddatum','Limit_Sw','Saldo_Sw','batchid','Oldkontonr','Forandring','Ny_limit_sw','Ny_saldo_sw','Start_Datum']






Main_Path=r'C:\Users\rso363\RONSEN\Python\Konton\Indata\Test_data2.csv'
chunksize = 10000*1000



for df in pd.read_csv(Main_Path, sep=';',encoding = "ISO-8859-1", low_memory=False,iterator=True,chunksize=chunksize,header=None):
    df.to_sql('data', conn, if_exists='append')

print((time.clock()-t)/100)

df2 = pd.read_sql_query('SELECT count(*) FROM data ', conn)


t=time.clock()
sql= """

SELECT  distinct Extr_datum ,Engagemangs_Datum  FROM Data    
where Konto_slutdatum in ("1900-01-01") and Kredittyp in ("1","2","3","4","5") and date(Extr_datum)=date(Extr_datum,"start of month") and 
(strftime("%m",  Extr_datum) + 12*strftime("%Y", Extr_datum))-(strftime("%m",  Engagemangs_Datum) + 12*strftime("%Y", Engagemangs_Datum))=2 
LIMIT 5

"""

df2 = pd.read_sql_query(sql, conn)
print((time.clock()-t)/60)

df2.info()

# Be sure to close the connection
conn.close()



sqlite3_table=[str(Calendar),str(Costumers),str(Master_file),str(Updated),str(Status),'BI_Logo','Kund_logo']
conn = sqlite3.connect(Out_path_DataBase+'\MY_SQLITE_DATABSE.db')
c = conn.cursor()

for tables in sqlite3_table:
    dropTableStatement = 'DROP TABLE IF EXISTS'+' '+  tables
    c.execute(dropTableStatement)

globals()[str(Calendar)+'1'].to_sql(str(Calendar), conn, if_exists='replace')
globals()[str(Costumers)+'1'].to_sql(str(Costumers), conn, if_exists='replace')
globals()[str(Master_file)+'1'].to_sql(str(Master_file), conn, if_exists='replace')
globals()[str(Updated+'1')].to_sql(str(Updated), conn, if_exists='replace')
globals()[str(Status+'1')].to_sql(str(Status), conn, if_exists='replace')
BI_Logo.to_sql('BI_Logo', conn, if_exists='replace')
Kund_logo.to_sql('Kund_logo', conn, if_exists='replace')



#please close the connection
conn.close()

**********************************************************************************************



******************mail

import smtplib
import email
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
from email.mime.multipart import MIMEMultipart

fromAddr="ronny.kizito@gmail.com"
toAddr=("ronny.sentongo@enfogroup.com","ronnysentongo@hotmail.com")

content ='Hello World'
#msg=MIMEMultipart()
#msg['from']=fromAddr
#msg['to']=toAddr
#msg['Subject']='test email'
#body='this is the content'
#msg.attach(MIMEText(body,'plain'))

mail = smtplib.SMTP('smtp.gmail.com',587)

mail.ehlo()

mail.starttls()
mail.login('ronny.kizito@gmail.com','1299se1299se')



mail.sendmail(fromAddr,toAddr,content)

mail.close()

**********************************zip
import zipfile
import pandas as pd

Main_Path=r'C:\Users\rso363\RONSEN\Master.zip'

with zipfile.ZipFile(Main_Path) as zippa:
   with zippa.open("New_file.xlsx") as file:
      df = pd.read_excel(file, header=None)


from zipfile import ZipFile

Main_Path=r'C:\Users\F2531197\Downloads\data.zip'
zip_file = ZipFile(Main_Path)
dfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))
       for text_file in zip_file.infolist()
       if text_file.filename.endswith('.csv')}
dfx = pd.concat(dfs.values(), axis=0,sort=False)
dfx['Filename']=Main_Path

start_time = time.time()
# your code
elapsed_time = time.time() - start_time
t=time.strftime("%H:%M:%S", time.gmtime(elapsed_time))
print(t)
df['elapsed_time']=t




'''********************************************************fortknox****************************************************************************************'''
'''********************************************************Import packages****************************************************************************************'''
import pandas as pd
import datetime
import os



'''***************************************************************************************************************************************************************'''
'''***************************************************************************************************************************************************************'''

#the costumer

Kund="3. Arlandastadbil"

#define the main path

Main_Path=r'C:\Users\Admin\Esron BI Analyzr AB\Gruppwebbplats - Dokument\1. BIAnalyzr_Database\Python\1. Costumers\\'+Kund

#dimension tables
Master_file='Main.csv'
Master_Budget='Budget.csv'
Calendar='Calendar.csv'


'''***************************************************************************************************************************************************************'''
'''***************************************************************************************************************************************************************'''


'''**************************create folders************************************************************************************************************************'''

folders = ["1. Indata", "2. Data Mining","3. Data","4. Syntax","5. PowerPoint","6. Kundfarger","7. Log","8. Flyspeed","9. Databas"]
for num, folder_name in enumerate(folders, start=1):
    newpath = Main_Path+'\\'+folder_name
    if not os.path.exists(newpath):
        os.makedirs(newpath)


In_folder=Main_Path+'\\1. Indata\\1. Report\\'
Out_path=Main_Path+'\\2. Data Mining\\'


'''***************************************************************************************************************************************************************'''



'''**************************import files ending with extension***************************************************************************************************'''

files_names = os.listdir(In_folder)
File_name = [i for i in files_names if i.endswith('.xlsx')] #txt csv xlsx xlsm osv.
#get the main folder name
Last_path_name=os.path.basename(os.path.dirname(In_folder))



'''***************************************************************************************************************************************************************'''




'''***************************************************************************************************************************************************************'''

'''*************************************Program begins************************************************************************************************************'''




'''********************************************Read fortknox files*************************************************************************************************'''
df = pd.DataFrame()
for the_files in File_name:
    xlfname = In_folder+'\\'+the_files
    xl = pd.ExcelFile(xlfname)
    for sheet in xl.sheet_names:
            df_tmp = xl.parse(sheet,header=None,encoding = 'ISO-8859-1')
            df_tmp['Sheetname']=sheet
            df_tmp['Filename']=the_files
            df_tmp['Last_Path_Name']=Last_path_name
            df_tmp['Created_Date'] = datetime.datetime.now().strftime("%Y-%m-%d")
            df = df.append(df_tmp, ignore_index=True,sort=False)
            

Col_names=['Vernr', 'Bokforingsdatum','Registreringsdatum','Konto', 'Benamning','Ks','Projnr', 'Verifikationstext','Transaktionsinfo','Debet', 'Kredit']
                         #rename the columns
for num, The_Col_names in enumerate(Col_names, start=0):
    df.rename(index=str, columns={num: The_Col_names},inplace=True)

df=df.query('Vernr not in ["Vernr"] and Sheetname not in ["obs","Kontoplan"] ')    




#to float or int   
New_data_type=['Debet','Kredit']
for The_Vars in New_data_type:
    df[str(The_Vars)] = df[str(The_Vars)].astype(float)
    
#to str 
New_data_type=['Konto','Vernr']
for The_Vars in New_data_type:
    df[str(The_Vars)] = df[str(The_Vars)].astype(str)

#to date
New_data_type=['Bokforingsdatum','Registreringsdatum']
for The_Vars in New_data_type:
    df[str(The_Vars)] = df[str(The_Vars)].values.astype("datetime64[s]")  

#if Nan then change to something
New_fillna=['Debet','Kredit']
for the_vars_fillna in New_fillna:
    df[str(the_vars_fillna)].fillna(0, inplace=True)


df['Manad']=df.Bokforingsdatum.dt.strftime('%Y-%m-01')
df['Summa']=-1*df.Debet+df.Kredit
df['Summax']=df.Debet-df.Kredit

#substring
df['Knr'] = df.Konto.str[0:2] 

#concatanate
df['com']=df.Vernr.str.cat([df.Konto,df.Konto],sep=', ')






df1 = df[['Vernr','Bokforingsdatum', 'Registreringsdatum', 'Konto','Knr', 'Benamning','Verifikationstext','Debet', 'Kredit','Summa','Manad','Summax','Filename']]


'''********************************************************End****************************************************************************************'''



'''*****************************************read help files********************************************************************************************'''

#read the help file

df = pd.read_excel(Main_Path+'\\1. Indata\\3. Helpfiles\\KontobasPlan.xlsx',header=None,encoding = 'ISO-8859-1')

Col_names=['Knr','Sammanfattning','Sammanfattning1','Sammanfattning2','Sammanfattning3','Kontroll']
for num, The_Col_names in enumerate(Col_names, start=0):
    df.rename(index=str, columns={num: The_Col_names},inplace=True)


#to str 
New_data_type=['Knr']
for The_Vars in New_data_type:
    df[str(The_Vars)] = df[str(The_Vars)].astype(str)
    
df2=df.query('Knr not in ["Knr"]')


'''********************************************************end*******************************************************************************************'''


'''***************************************************merge files*********************************************************************************************'''

df3=pd.merge(df1,df2[['Knr','Sammanfattning','Sammanfattning1','Sammanfattning2', 'Sammanfattning3','Kontroll']],how="left",left_on=["Knr"],right_on=["Knr"])  

'''********************************************************end*******************************************************************************************'''

'''***************************************************Analys to PBI*********************************************************************************************'''


df4=df3.groupby(['Sammanfattning','Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
df4.columns = ["_".join(x) for x in df4.columns.ravel()]
df4=df4.query('Sammanfattning_ in ["NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter","RÃ¶relsekostnader",'
'"Ã–vriga externa rÃ¶relsekostnader","Personalkostnader","Finansiella poster"]')




'''****************************************sum Summa rorelseintÃ¤kter*********************************************************************************************'''
Dataset=('df5')
dfx=df3.query('Sammanfattning in ["NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter"]')

globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'Summa rÃ¶relseintÃ¤kter'



'''****************************************sum Summa Bruttovinst*********************************************************************************************'''

Dataset=('df6')
dfx=df3.query('Sammanfattning in ["NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter","RÃ¶relsekostnader"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'Bruttovinst'

'''****************************************sum Summa Roreskostnader*********************************************************************************************'''

Dataset=('df7')
dfx=df3.query('Sammanfattning in ["RÃ¶relsekostnader","Ã–vriga externa rÃ¶relsekostnader","Personalkostnader"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'Summa RÃ¶relsekostnader'


'''****************************************rorelseresultat*********************************************************************************************'''

Dataset=('df8')
dfx=df3.query('Sammanfattning in ["RÃ¶relsekostnader","Ã–vriga externa rÃ¶relsekostnader","Personalkostnader","NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'RÃ¶relseresultat'

'''****************************************resultat efter avskrivningar*********************************************************************************************'''

Dataset=('df9')
dfx=df3.query('Sammanfattning1 in ["Avskrivningar"] or Sammanfattning in ["RÃ¶relsekostnader","Ã–vriga externa rÃ¶relsekostnader","Personalkostnader","NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'Resultat efter avskrivningar'

'''****************************************resultatrakning*********************************************************************************************'''



'''****************************************resultat efter finaiellaposter*********************************************************************************************'''
Dataset=('df10')
dfx=df3.query('Sammanfattning1 in ["Avskrivningar"] or  ' 
'Sammanfattning in ["RÃ¶relsekostnader","Ã–vriga externa rÃ¶relsekostnader","Personalkostnader","NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter","Finansiella poster"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'RESULTAT EFTER FINASIELLA POSTER'

'''****************************************resultat efter finaiellaposter och dispositioner****************************************************************'''
Dataset=('df11')
dfx=df3.query('Sammanfattning1 in ["Avskrivningar"] or  ' 
'Sammanfattning in ["RÃ¶relsekostnader","Ã–vriga externa rÃ¶relsekostnader","Personalkostnader","NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter","Finansiella poster","ExtraordinÃ¤ra poster","Bokslutsdispositioner"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'RESULTAT efter finansiella poster och dispositioner'

'''****************************************Beraknat resultat****************************************************************'''
Dataset=('df12')
dfx=df3.query('Sammanfattning1 in ["Avskrivningar"] or  ' 
'Sammanfattning in ["RÃ¶relsekostnader","Ã–vriga externa rÃ¶relsekostnader","Personalkostnader","NettoomsÃ¤ttning","Ã–vriga rÃ¶relseintÃ¤kter","Finansiella poster","ExtraordinÃ¤ra poster","Bokslutsdispositioner","Skatt"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'BERÃ„KNAT RESULTAT'



'''****************************************resultatrakning*********************************************************************************************'''

df_final=pd.concat([df4,df5,df6,df7,df8,df9,df10,df11,df12],sort=False)

#if else statement
dataset=df_final
The_var=('Sammanfattning_')
New_var=('Rank_var')
dataset.loc[dataset[str(The_var)].isin(['NettoomsÃ¤ttning']), str(New_var)] = 1
dataset.loc[dataset[str(The_var)].isin(['Ã–vriga rÃ¶relseintÃ¤kter']), str(New_var)] = 2
dataset.loc[dataset[str(The_var)].isin(['Summa rÃ¶relseintÃ¤kter']), str(New_var)] = 3
dataset.loc[dataset[str(The_var)].isin(['RÃ¶relsekostnader']), str(New_var)] = 4
dataset.loc[dataset[str(The_var)].isin(['Bruttovinst']), str(New_var)] = 5
dataset.loc[dataset[str(The_var)].isin(['Ã–vriga externa rÃ¶relsekostnader']), str(New_var)] = 6 
dataset.loc[dataset[str(The_var)].isin(['Personalkostnader']), str(New_var)] = 7
dataset.loc[dataset[str(The_var)].isin(['Summa RÃ¶relsekostnader']), str(New_var)] = 8
dataset.loc[dataset[str(The_var)].isin(['RÃ¶relseresultat']), str(New_var)] = 9
dataset.loc[dataset[str(The_var)].isin(['Resultat efter avskrivningar']), str(New_var)] = 10
dataset.loc[dataset[str(The_var)].isin(['Finansiella poster']), str(New_var)] = 11
dataset.loc[dataset[str(The_var)].isin(['RESULTAT EFTER FINASIELLA POSTER']), str(New_var)] = 12
dataset.loc[dataset[str(The_var)].isin(['RESULTAT efter finansiella poster och dispositioner']), str(New_var)] = 13
dataset.loc[dataset[str(The_var)].isin(['BERÃ„KNAT RESULTAT']), str(New_var)] = 14



 
df_final.to_csv(Out_path+'\\test.csv',sep=';', index=False,decimal=',',encoding='ISO-8859-1')


'''********************************************************end resultatrakning*******************************************************************************************'''

'''*********************************************start balansrakning*******************************************************************************************'''


'''****************************************Finansiella anlaggningstillgÃ¥ngar ****************************************************************'''

Dataset=('df5')
dfx=df3.query('Sammanfattning in ["Finansiella anlÃ¤ggningstillgÃ¥ngar (lÃ¥ngfristiga fordringar)"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'Finansiella anlÃ¤ggningstillgÃ¥ngar (lÃ¥ngfristiga fordringar)'
globals()[str(Dataset)].Summa_sum=globals()[str(Dataset)].Summa_sum*-1


'''****************************************Finansiella anlaggningstillgÃ¥ngar ****************************************************************'''

Dataset=('df6')
dfx=df3.query('Sammanfattning1 in ["Summa anlÃ¤ggningstillgÃ¥ngar"]')
globals()[str(Dataset)]=dfx.groupby(['Manad'], as_index=False).agg({"Summa": ["sum"]})
#denna fixar till namnen som skapas av groupby
globals()[str(Dataset)].columns = ["_".join(x) for x in globals()[str(Dataset)].columns.ravel()]

globals()[str(Dataset)].loc[:, 'Sammanfattning_'] = 'Summa anlÃ¤ggningstillgÃ¥ngar'
globals()[str(Dataset)].Summa_sum=globals()[str(Dataset)].Summa_sum*-1
globals()[str(Dataset)]['Summa'] = globals()[str(Dataset)].groupby(['Sammanfattning_'])['Summa_sum'].apply(lambda x: x.cumsum())


#%%

#%%
import pandas as pd
import datetime
import os
import time
import sqlite3

t=time.clock()

encoding="ISO-8859-1" #'utf-8-sig'


# The costumer name here
Kund="1. Din Lon"

Kund_logo={'Kund_logo':['http://www.dinlon.se/wp-content/themes/din-lon/img/logo%20-%20din%20lon%20-%20blue.svg']}
Kund_logo = pd.DataFrame(Kund_logo)

BI_Logo={'BI_Logo':['http://bianalyzr.se/images/templates/palett/logo.png']}
BI_Logo = pd.DataFrame(BI_Logo)


#Define the main path here 
Main_Path=r'C:\Users\Admin\Esron BI Analyzr AB\Gruppwebbplats - Dokument\1. BIAnalyzr_Database\Python\1. Costumers\\'+Kund

#create the folders for the rapport
folders = ["1. Indata", "2. Data Mining","3. Data","4. Syntax","5. PowerPoint","6. Kundfarger","7. Log","8. Flyspeed","9. Databas"]
for num, folder_name in enumerate(folders, start=1):
    newpath = Main_Path+'\\'+folder_name
    if not os.path.exists(newpath):
        os.makedirs(newpath)


#the path for the indata files
In_folder=Main_Path+'\\fakturamall 2018\\'

#the path for the out data
Out_path=Main_Path+'\\2. Data Mining\\'
Out_path_DataBase=Main_Path+'\\9. Databas\\'

#
##.......................create dimension tables

#the masterfile
Master_file=('Master_Din_Lon')
Costumers=('Costumers')
Calendar=('Calendar')
Updated=('Updated')
Status=('Status')
#...................................................................................................



#.............................program start

# get all files in the folder with ext 
files_names = os.listdir(In_folder)
File_name = [i for i in files_names if i.endswith('.xlsm')] #txt csv xlsx xlsm osv.
#get the main folder name
Last_path_name=os.path.basename(os.path.dirname(In_folder))


df = pd.DataFrame()
for the_files in File_name:
    xlfname = In_folder+'\\'+the_files
    xl = pd.ExcelFile(xlfname)
    for sheet in xl.sheet_names:
            df_tmp = xl.parse(sheet,header=None,usecols = [8,9,10,11,12],nrows=150)
            df_tmp['Sheetname']=sheet
            df_tmp['Filename']=the_files
            df_tmp['Last_Path_Name']=Last_path_name
            df = df.append(df_tmp, ignore_index=True,sort=False)



df.rename(index=str, columns={0: "Artikel",1: "Pris",2: "Antal",3: "Summa",4: "Nummer"},inplace=True)
#substr last n letters opposite will be [:9]
#df['File_name2'] = df.Filename.str[-9:]
df['AR'] = df.Last_Path_Name.str.rsplit(" ", expand=True)[1]

#substr
df['man'] = df.Sheetname.str[0:3]


#upcase--str.upper(), lowcase--str.lower() propcase--str.title()
df['man1'] = df.man.str.lower()
df['Created_Date'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")

#if else statement
#get the swedish monthname by nummber
dataset=df
The_var=('man1')
New_var=('Month_Swe')
dataset.loc[dataset[str(The_var)].isin(['jan']), str(New_var)] = '01'
dataset.loc[dataset[str(The_var)].isin(['feb']), str(New_var)] = '02'
dataset.loc[dataset[str(The_var)].isin(['mar']), str(New_var)] = '03'
dataset.loc[dataset[str(The_var)].isin(['apr']), str(New_var)] = '04'
dataset.loc[dataset[str(The_var)].isin(['maj']), str(New_var)] = '05'
dataset.loc[dataset[str(The_var)].isin(['jun']), str(New_var)] = '06'
dataset.loc[dataset[str(The_var)].isin(['jul']), str(New_var)] = '07'
dataset.loc[dataset[str(The_var)].isin(['aug']), str(New_var)] = '08'
dataset.loc[dataset[str(The_var)].isin(['sep']), str(New_var)] = '09'
dataset.loc[dataset[str(The_var)].isin(['okt']), str(New_var)] = '10'
dataset.loc[dataset[str(The_var)].isin(['nov']), str(New_var)] = '11'
dataset.loc[dataset[str(The_var)].isin(['dec']), str(New_var)] = '12'


df['Datum']=df.AR+'-'+df.Month_Swe+'-'+'01'

#remove duplicates

df.drop_duplicates(['Artikel','Pris','Antal','Summa','Nummer','Datum','Filename'],keep= 'last', inplace=True)
df = df.assign(ID_Kund=(df['Filename']).astype('category').cat.codes)
#make a unique id, I find this important for my analyses in the BI tools
df['IDx'] = 1
df['ID']=df.IDx.cumsum()



#%%
#all costumers


uniqueVals= df["Filename"].unique()


uniqueVals = pd.DataFrame(uniqueVals)
uniqueVals.rename(index=str, columns={0: "Kund"},inplace=True)


#dont change the dataframe name here, change in the beginning of the syntax
globals()[str(Costumers)+'1'] =uniqueVals


globals()[str(Costumers+'1')].to_csv(Out_path+str(Costumers)+'.csv',sep=';', index=False,decimal=',', encoding=encoding)

#%%

#updated


uniqueVals= df["Created_Date"].unique()


uniqueVals = pd.DataFrame(uniqueVals)
uniqueVals.rename(index=str, columns={0: "Updated"},inplace=True)


#dont change the dataframe name here, change in the beginning of the syntax
globals()[str(Updated)+'1'] =uniqueVals


globals()[str(Updated+'1')].to_csv(Out_path+str(Updated)+'.csv',sep=';', index=False,decimal=',', encoding=encoding)




#%%

#create a status dataframe here
#match this to the main table by id
	
df_status= df.loc[df['Pris'] == 'EJ KLAR']
df_status = df_status.rename(columns={'Pris': 'Status'})
df_status = df_status[['Status', 'ID', 'Datum','Filename','ID_Kund']]



#%%
#..................................................................
#waggling the data

#drop all empty rows in a column
df.dropna(subset=['Artikel','Nummer'], inplace=True)
#drop all row with value

#drp all empty columns df=df.dropna(how='all')

df=df.query('Artikel not in ["Artikel"]') 
#df.drop(df.loc[df.Artikel.isin(['Artikel'])].index, inplace=True)	
	

#a fuction for change from str to num or otherway around

def coerce_df_columns_to_numeric(df, column_list):
    df[column_list] = df[column_list].apply(pd.to_numeric, errors='coerce')

coerce_df_columns_to_numeric(df, ['Pris','Antal','Summa','Nummer'])

#the sum must be greater than zero in this report
df = df.loc[(df.Summa>0)  ]

#the keys must insert for chosing a new vars otherwise it brings all colums
df3= pd.merge(df,df_status[['Filename','Datum','Status']], how="left", left_on=['Filename','Datum'], right_on=['Filename','Datum'],indicator=True)
#df.info()

#if Nan then change to something

df3.Status.fillna('KLAR', inplace=True)


#df_test=df3.Nummer.fillna(df3['Nummer'].mean()) 

#dont change the dataframe name here, change in the beginning of the syntax

globals()[str(Master_file)+'1']=df3[["Sheetname","Filename","Artikel","Pris","Antal","Summa","Nummer","Datum","Status"]]

#df.info()
globals()[str(Master_file)+'1'].to_csv(Out_path+str(Master_file)+'.csv',sep=';', index=False,decimal=',', encoding=encoding)


#%%

#status


uniqueVals= globals()[str(Master_file)+'1']["Status"].unique()


uniqueVals = pd.DataFrame(uniqueVals)
uniqueVals.rename(index=str, columns={0: "Status"},inplace=True)


#dont change the dataframe name here, change in the beginning of the syntax
globals()[str(Status)+'1'] =uniqueVals


globals()[str(Status+'1')].to_csv(Out_path+str(Status)+'.csv',sep=';', index=False,decimal=',', encoding=encoding)
        
#%%
#the calander
#dont change anything here
Min_date=str(globals()[str(Master_file)+'1'].Datum.min())
Max_date=str(globals()[str(Master_file)+'1'].Datum.max())


import pandas as pd
from datetime import timedelta
#from dateutil.relativedelta import relativedelta
from pandas.tseries.offsets import MonthEnd
#df['dates'] = pd.date_range(start='2017-01-01',end='2017-01-31',freq='D')

def create_date_table2(start, end,freq='D'):
    df = pd.DataFrame({"Date": pd.date_range(start, end)})
    df["Year"] = df.Date.dt.year
    df["NextYear"] = df.Date.dt.year+1
    df["DayofWeek"] = df.Date.dt.weekday_name
    df["DayNumber"] = df.Date.dt.weekday+1
    df["MonthNumber"] = df.Date.dt.month
    df["Week"] = df.Date.dt.weekofyear
    df["Qtr"] = df.Date.dt.quarter
    df['MonthBegin'] = df.Date.values.astype('datetime64[M]')
    df['YearBegin'] = df.Date.values.astype('datetime64[Y]')
    df['MonthEnd'] = pd.to_datetime(df.Date, format="%Y%m") + MonthEnd(0)
    df['date1'] = pd.Timestamp('2019-01-01')
    df['months_between'] = (df.date1.dt.to_period('M') - df.Date.dt.to_period('M'))
    df['days_between'] = (df.date1.dt.to_period('D') - df.Date.dt.to_period('D'))
    df['weeks_between'] = (df.date1.dt.to_period('w') - df.Date.dt.to_period('w'))
    df['date_N_days_ago'] = df.Date + timedelta(days=2)
    df['Rank']= df.Date.dt.strftime('%Y%m').astype(int)
    df['Manad']= df.Date.dt.strftime('%Y-%m')
    df['MonthName']= df.Date.dt.strftime('%B')
    df['MonthName1']= df.Date.dt.strftime('%b')
    df['Previous_month'] = df.Date - pd.DateOffset(months=1)
    df['Next_month'] = df.Date + pd.DateOffset(months=1)
    df['Next_Week'] = df.Date + pd.DateOffset(weeks=1)
    df['Previous_Week'] = df.Date - pd.DateOffset(weeks=1)
    df['Next_WeekNumber'] = df.Next_Week.dt.weekofyear
    df['Previous_WeekNumber'] = df.Previous_Week.dt.weekofyear
    df['yy']= df.Date.dt.strftime('%y')
    return df

MyCalendar=create_date_table2(start=Min_date, end=Max_date,freq='D')


dataset=MyCalendar
The_var=('man1')
New_var=('Month_Swe')
dataset.loc[dataset[str(The_var)].isin(['jan']), str(New_var)] = '01'
dataset.loc[dataset[str(The_var)].isin(['feb']), str(New_var)] = '02'
dataset.loc[dataset[str(The_var)].isin(['mar']), str(New_var)] = '03'
dataset.loc[dataset[str(The_var)].isin(['apr']), str(New_var)] = '04'
dataset.loc[dataset[str(The_var)].isin(['maj']), str(New_var)] = '05'
dataset.loc[dataset[str(The_var)].isin(['jun']), str(New_var)] = '06'
dataset.loc[dataset[str(The_var)].isin(['jul']), str(New_var)] = '07'
dataset.loc[dataset[str(The_var)].isin(['aug']), str(New_var)] = '08'
dataset.loc[dataset[str(The_var)].isin(['sep']), str(New_var)] = '09'
dataset.loc[dataset[str(The_var)].isin(['okt']), str(New_var)] = '10'
dataset.loc[dataset[str(The_var)].isin(['nov']), str(New_var)] = '11'
dataset.loc[dataset[str(The_var)].isin(['dec']), str(New_var)] = '12'


MyCalendar['Datum_swe']= 'x'+MyCalendar.Month_Swe+'-'+MyCalendar.yy

#MyCalendar['start_next_month'] = datetime.datetime(MyCalendar.v.year, MyCalendar.v.month, 1)
#MyCalendar['Date'] = pd.to_datetime(MyCalendar.Date)


#dont change the dataframe name here, change in the beginning of the syntax
globals()[str(Calendar)+'1']=MyCalendar[["Date","Year","NextYear","DayofWeek","Datum_swe",'Rank']]

globals()[str(Calendar)+'1'].to_csv(Out_path+str(Calendar)+'.csv',sep=';', index=False,decimal=',',encoding=encoding)

#globals()[str(Calendar)+'1'].info()
#%%

BI_Logo.to_csv(Out_path+'BI_Logo.csv',sep=';', index=False,decimal=',',encoding=encoding)
Kund_logo.to_csv(Out_path+'Kund_logo.csv',sep=';', index=False,decimal=',',encoding=encoding)

#%%

print(time.clock()-t/100)


#%%

#create a database(sqlite3) for the out files, 

sqlite3_table=[str(Calendar),str(Costumers),str(Master_file),str(Updated),str(Status),'BI_Logo','Kund_logo']
conn = sqlite3.connect(Out_path_DataBase+'\MY_SQLITE_DATABSE.db')
c = conn.cursor()

for tables in sqlite3_table:
    dropTableStatement = 'DROP TABLE IF EXISTS'+' '+  tables
    c.execute(dropTableStatement)

globals()[str(Calendar)+'1'].to_sql(str(Calendar), conn, if_exists='replace')
globals()[str(Costumers)+'1'].to_sql(str(Costumers), conn, if_exists='replace')
globals()[str(Master_file)+'1'].to_sql(str(Master_file), conn, if_exists='replace')
globals()[str(Updated+'1')].to_sql(str(Updated), conn, if_exists='replace')
globals()[str(Status+'1')].to_sql(str(Status), conn, if_exists='replace')
BI_Logo.to_sql('BI_Logo', conn, if_exists='replace')
Kund_logo.to_sql('Kund_logo', conn, if_exists='replace')



#please close the connection
conn.close()

#%%
#%a 	Weekday, short version 	Wed 	
#%A 	Weekday, full version 	Wednesday 	
#%w 	Weekday as a number 0-6, 0 is Sunday 	3 	
#%d 	Day of month 01-31 	31 	
#%b 	Month name, short version 	Dec 	    
#%B 	Month name, full version 	December 	
#%m 	Month as a number 01-12 	12 	
#%y 	Year, short version, without century 	18 	
#%Y 	Year, full version 	2018 	
#%H 	Hour 00-23 	17 	
#%I 	Hour 00-12 	05 	
#%p 	AM/PM 	PM 	
#%M 	Minute 00-59 	41 	
#%S 	Second 00-59 	08 	
#%f 	Microsecond 000000-999999 	548513 	
#%z 	UTC offset 	+0100 	
#%Z 	Timezone 	CST 	
#%j 	Day number of year 001-366 	365 	
#%U 	Week number of year, Sunday as the first day of week, 00-53 	52 	
#%W 	Week number of year, Monday as the first day of week, 00-53 	52 	
#%c 	Local version of date and time 	Mon Dec 31 17:41:00 2018 	
#%x 	Local version of date 	12/31/18 	
#%X 	Local version of time 	17:41:00 	
#%% 	A % character 	%
#https://www.programiz.com/python-programming/library/strftime*/



#%%
Data = {'col_1': ['(908)235-4490', 'ronny123', 'Ronnysentongo@hotmail.com', 'ronny.kizito@gmail.com','ronny.sentongo@uc.se']}
df=pd.DataFrame.from_dict(Data)
df[['Name','email']] = df.col_1.str.rsplit('@',1, expand=True)
df[['Domain','ext']] = df.email.str.rsplit('.',1, expand=True)
df[['FirstName','LastName']] = df.Name.str.rsplit('.',1, expand=True)

#%%

Data = {'col_1': ['Judith S Reaveley', 'Ralf F. Morgan', 'Jess Ennis', 'Carol Echols','Kelly Hansen Huff','Judith','Nick','Jones','George W. Bush',
'George W Bush','George Bush','Dr. Smith T. Bauer MD','Samuel I Rodriguez M.D.','Will Glader MD']}
df=pd.DataFrame.from_dict(Data)

df['BrandName'] = [x.strip().replace('Dr.','') for x in df.col_1]
df['BrandName'] = df['BrandName'].str.strip()

df['firstnamn']=df.col_1.str.split('@').apply(lambda x: x[0])
df['lastnamn']=df.col_1.str.split('@').apply(lambda x: x[-1])

#%%


df = pd.DataFrame({
    'Date': ['2017-1-1', '2017-1-1', '2017-1-2', '2017-1-2', '2017-1-3'],
    'Groups': ['one', 'one', 'one', 'two', 'two'],
    'data': range(1, 6)})
    
df2=df.groupby(['Date','Groups'], as_index=False).agg({"data": ["sum"]})
#denna fixar till namnen som skapas av groupby
df2.columns = ["_".join(x) for x in df2.columns.ravel()]


df3=df.pivot_table(index='Date',columns='Groups',aggfunc=sum)

#delete files
import os

Delete_files=('testar - kopia.csv','testar - kopia (2).csv','testar - kopia.xlsx')
Main_Path=r'C:\Users\rso363\RONSEN\file1\\'

for Delete_file in Delete_files:
    myfile=Main_Path+Delete_file
    ## If file exists, delete it ##
    if os.path.isfile(myfile):
     os.remove(myfile)
    else:    ## Show an error ##
         print("Error: %s file not found" % myfile)


#sql server



#conn =  "DRIVER={ODBC Driver 17 for SQL Server};SERVER=IP_ADDRESS;DATABASE=DataLake;UID=USER;PWD=PASS"
import pandas as pd
import pyodbc
     
server = "DESKTOP-VPI7EHV\BIANALYZRTABULAR"
db = "RONSEN"
conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + server + ';DATABASE=' + db)

c = conn.cursor()


sql='''
select * from crm where Area='Works' and Status='Cancelled'
'''
df = pd.read_sql_query(sql, conn)


#tales
sql='''
select * from information_schema.tables
'''
df1 = pd.read_sql_query(sql, conn)

#columns
sql='''
select top 10 * from crm
'''
df1_info = pd.read_sql_query(sql, conn)
df1_info.info()
conn.close()


import pandas as pd
import datetime

def create_date_table2(start, end):
    df = pd.DataFrame({"Date": pd.date_range(start, end,freq='YS')})
    df['AR1']= df.Date.dt.strftime('%Y').astype(int)
    df['AR2']= df.AR1-1
    df['Period']=df.AR2.astype(str).str.cat([df.AR1.astype(str)],sep='-')
    df['AR1x']= df.Date.dt.strftime('%y').astype(int)
    df['AR2x']= df.AR1x-1
    df['Periodx']=df.AR2x.astype(str).str.cat([df.AR1x.astype(str)],sep='')
    return df
df1=create_date_table2(start='2018-01-01', end='2019-01-01')



period_l = df1.Period.tolist()
period_s = df1.Periodx.tolist()



columns=['Date','Div']
df = pd.DataFrame()
for yyyymm,yymm in zip(period_l, period_s):
    xlfname = 'http://www.football-data.co.uk/mmz4281/'+str(yymm)+'/all-euro-data-'+str(yyyymm)+'.xlsx'
    xl = pd.ExcelFile(xlfname)
    for sheet in xl.sheet_names:
        df_tmp = xl.parse(sheet)
        df_tmp=df_tmp[columns].copy()
        df_tmp['Filename']=str(yyyymm)
        df_tmp['Sheetname']=sheet
        df_tmp['Created_Date'] = datetime.datetime.now().strftime("%Y-%m-%d")
        df = df.append(df_tmp, ignore_index=True,sort=False)



import pyodbc
from sqlalchemy import create_engine
import urllib
import pandas as pd


server_out='PF15AYH5'
database='AdventureWorks2017'
 
params = urllib.parse.quote_plus(r'DRIVER={SQL Server};SERVER='+server_out+';DATABASE='+database+';Trusted_Connection=yes')
conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)
conn_out = create_engine(conn_str)

sql=''' 
SELECT sum(bonus) as bonus
  FROM Sales.SalesPerson
'''
df = pd.read_sql_query(sql, conn_out)





PWBI_replace_numeric=['bonus']
df[PWBI_replace_numeric] = df[PWBI_replace_numeric].values.astype(str) 

for replace_dot_comma in PWBI_replace_numeric:
    df[replace_dot_comma] = df[replace_dot_comma].str.replace('.', ',')


#df.to_csv(Main_Path+'\\test2.csv',sep=';', index=False,decimal=',',encoding='ISO-8859-1')
df = pd.DataFrame(index = pd.date_range('2018-01-01', '2019-12-31', freq='D'))
df['Date']=df.index
df['Value'] = np.random.randint(0,5, size=len(df))

df['SamePeriodLastYear'] = df.groupby([df['Date'].dt.month,df['Date'].dt.day])['Value'].shift()

read multi excel
all_Files = glob.glob('/home/data/*.xlsx')

df = pd.concat((pd.read_excel(files, sep=',', index=False, skiprows=1) for files in all_Files))

# intertool
df=pd.DataFrame({'Date':['f']})
df_tmp=pd.DataFrame()
for r in itertools.product(Dates, list2):
    df['a']=r[0] 
    df['b']=r[1]
    df_tmp = df_tmp.append(df, ignore_index=True,sort=False)

#month to int
df['Manad']=(pd.to_datetime(df.Man, format='%b').dt.month).astype(str).str.pad(width=2,fillchar='0')
